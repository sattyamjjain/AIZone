{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>H.O.G. and SVM Image Classification with OpenCV and <a href=\"https://vision.skills.network/\"> Computer Vision Learning Studio (CV Studio)</a></h2></h2>\n",
    "<h3>Project: Training_an_image_classifier_with_SVM</h3>\n",
    "<h3>Training Run: Train SVM image classifier</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn how to train images with Support  Vector Machines (SVM). SVM is a supervised  learning  model that analyze data used for classification and regression analysis. We will be using SVM to classify images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be classifying images using <code>Sklearn</code> and <a href=\"https://vision.skills.network/\"> Computer Vision Learning Studio (CV Studio)</a>. CV Studio is a fast, easy and collaborative open-source Computer Vision tool for teams and individuals. You can upload your datasets and label them yourself. If you created a separate folder for each image class, the tool will do the labeling for you. H.O.G. combined with SVM was one of the ways image classification was done before more advanced methods like Deep Learning became popular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>This tool contains the following sections:\n",
    "        <ul>\n",
    "            <li>Import Libraries</li>\n",
    "            <li>Image Files and Paths  </li>\n",
    "            <li>Plotting an Image </li>\n",
    "            <li>H.O.G. as a feature descriptor </li>\n",
    "            <li>SVM for Image classification </li>\n",
    "            <li>Save your model to CVStudio</li>\n",
    "            <li>What's Next</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Important Libraries and Define Auxilary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for data processing and visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for image pre-processing and classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for OS and Cloud:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skillsnetwork import cvstudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load and process every image. Let's go over some concepts:\n",
    "\n",
    "<ul>\n",
    "        <ul>\n",
    "            <li><code>cv2.resize()</code> to resize the image </li>\n",
    "            <li><code>cv2.COLOR_BGR2GRAY()</code> will convert the images to greyscale image</li>\n",
    "            <li><code>hog()</code> will get the H.O.G. features from the image </li>\n",
    "        </ul>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "We will use this function to read and preprocess the images, the function will be explained in the **Histogram of Oriented Gradients (H.O.G.)** section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    # loop over the input images\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        # read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = np.array(image).astype(\"uint8\")\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        grey_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        hog_features, hog_images = hog(\n",
    "            grey_image, visualize=True, block_norm=\"L2-Hys\", pixels_per_cell=(16, 16)\n",
    "        )\n",
    "        # label image using the annotations\n",
    "        label = class_object.index(\n",
    "            annotations[\"annotations\"][image_path[7:]][0][\"label\"]\n",
    "        )\n",
    "        train_images.append(hog_features)\n",
    "        train_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Your Images and Annotations\n",
    "We will train and classify them using the SVM classifier using the <code>Sklearn</code> library. Before we start, let's get the images and take a look at some of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CV Studio Client\n",
    "cvstudioClient = cvstudio.CVStudio()\n",
    "\n",
    "# Download All Images\n",
    "cvstudioClient.downloadAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the annotations from CV Studio:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = cvstudioClient.get_annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the format of the annotations we've just downloaded. The following code will display only the first 5 annotations. The annotations will come in a JSON file. What you can see is the image name as the key and dog as label object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five = {\n",
    "    k: annotations[\"annotations\"][k] for k in list(annotations[\"annotations\"])[:5]\n",
    "}\n",
    "first_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Oriented Gradients (H.O.G.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H.O.G. generates a histogram for each localized region. We will pick a random image and see how H.O.G. works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = \"images/\" + random.choice(list(annotations[\"annotations\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create H.O.G. features, we will first convert the image to a grayscale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = cv2.imread(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the image to a smaller size to allow the algorithm to run faster and convert the images to the grayscale to reduce the number of channels. `OpenCV` reads images as `BGR` so we will be using that color channel to convert to grayscale. \n",
    "\n",
    "Early developers at `OpenCV` chose `BGR` color format because it was the format that was popular among camera manufacturers and software providers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = cv2.resize(sample_image, (64, 64))\n",
    "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data to look at what it looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run H.O.G. on the grayscale image to see what it will look like.\n",
    "\n",
    "H.O.G. stands for Histogram of Oriented Gradients. It uses the gradient orientation of the localized regions of an image and generates a histogram for each localized region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## when we run H.O.G., it returns an array of features and the image/output it produced\n",
    "## the featurre is what we use to train the SVM model\n",
    "sample_image_features, sample_hog_image = hog(\n",
    "    sample_image, visualize=True, block_norm=\"L2-Hys\", pixels_per_cell=(16, 16)\n",
    ")\n",
    "\n",
    "## lets look at what the H.O.G. feature looks like\n",
    "plt.imshow(sample_hog_image, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Generate Training/Testing Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate a location for saving loaded images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(paths.list_images(\"images\"))\n",
    "train_images = []\n",
    "train_labels = []\n",
    "class_object = annotations[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function on the image path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of the images and use the <code>np.vstack</code> to vertically stack arrays for wrangling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.array(train_images)\n",
    "train_array = np.vstack(train_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will <code>reshape</code> the array to <code>(label size, 1)</code>. The array will look like this: <code>[[1], [0], ..., [0]]</code></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = labels_array.astype(int)\n",
    "labels_array = labels_array.reshape((labels_array.size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the images and labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = np.concatenate([train_array, labels_array], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into a training and test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 75\n",
    "partition = int(len(train_df) * percentage / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_df[:partition, :-1], train_df[partition:, :-1]\n",
    "y_train, y_test = train_df[:partition, -1:].ravel(), train_df[partition:, -1:].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel type to be used is a hyperparameter. The most common kernels are <code>RBF</code>, <code>poly</code>, or <code>sigmoid</code>. You can also create your own kernel.\n",
    "\n",
    "<code>C</code> behaves as a regularization parameter in the SVM. The <code>C</code> parameter trades off correct classification of the training examples against the maximization of the decision function’s margin. For larger values of <code>C</code>, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower <code>C</code> will encourage a larger margin, therefore a simpler decision function at the cost of accuracy. We select C and the best kernel by using the validation data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  python dictionary <code>param_grid</code>  has different kernels and values of C. We can test them using the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>gamma</code> is a parameter of the RBF kernel and can be thought of as the spread of the kernel and, therefore, the decision region. Low values mean ‘far’ and high values mean ‘close’. The behaviour of the model is very sensitive to the gamma parameter. If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself. We create a Support Vector Classification object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = SVC(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model and try different kernels and parameter values using the function <code>GridSearchCV</code>. The resulting output will be the model that performs best on the validation data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = datetime.now()\n",
    "start = time.time()\n",
    "\n",
    "svm = GridSearchCV(base_estimator, param_grid, cv=5)\n",
    "# Fit the data into the classifier\n",
    "svm.fit(x_train, y_train)\n",
    "# Get values of the grid search\n",
    "best_parameters = svm.best_params_\n",
    "print(best_parameters)\n",
    "# Predict on the validation set\n",
    "y_pred = svm.predict(x_test)\n",
    "# Print accuracy score for the model on validation  set.\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "end = time.time()\n",
    "end_datetime = datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Quick Guide to the Confusion Matrix**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a performance measurement for a classification problem. It is a table with a combination of predicted and actual values. On the y-axis, we have the `True` label and on the x-axis we have the `Predicted` label. This example will focus on a binary classifier, i.e. a yes or no model.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>&nbsp;</td>\n",
    "    <td>Predicted: NO</td>\n",
    "    <td>Predicted: YES</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: NO</td>\n",
    "    <td>30</td>\n",
    "    <td>30</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: YES</td>\n",
    "    <td>10</td>\n",
    "    <td>50</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "In this matrix, we can see that there are two classes. For example, if we were predicting if an image is a hotdog, \"yes\" will be that it is a hotdog and \"no\" will be that it is not a hotdog. We have 120 predictions and out of those times, the classifier predicted \"yes\" 80 times and \"no\" 40 times but really, there were 60 \"yes\"s and 60 \"no\"s.\n",
    "\n",
    "When we talk about confusion matrix, we talk about a few terms:\n",
    "* True Positive (TP): Our model predicted \"yes\", and it was actually \"yes\"\n",
    "* True Negative (TN): Our model predicted \"no\", and it was actually \"no\"\n",
    "* False Positive (FP): Our model predicted \"yes\", but it was actually \"no\"\n",
    "* False Negative (FN): Our model predicted \"no\", but it was actually \"yes\"\n",
    "\n",
    "Let's look at it in the context of our example:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>&nbsp;</td>\n",
    "    <td>Predicted: NO</td>\n",
    "    <td>Predicted: YES</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: NO</td>\n",
    "    <td>TN = 30</td>\n",
    "    <td>FP = 30</td>\n",
    "    <td>60</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: YES</td>\n",
    "    <td>FN = 10</td>\n",
    "    <td>TP = 50</td>\n",
    "    <td>60</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&nbsp;</td>\n",
    "    <td>40</td>\n",
    "    <td>80</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Accuracy** is the number the model got right over the total number of predictions. This is (TP+TN)/Total Number of Predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Confusion Matrix for SVM results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [0, 1]\n",
    "cmx = confusion_matrix(y_test, y_pred, labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cmx)\n",
    "# plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4)  # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})  # font size\n",
    "title = \"Confusion Matrix for SVM results\"\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Report Our Results Back to CV Studio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"best_params\": best_parameters}\n",
    "result = cvstudioClient.report(\n",
    "    started=start_datetime,\n",
    "    completed=end_datetime,\n",
    "    parameters=parameters,\n",
    "    accuracy=accuracy_score(y_test, y_pred),\n",
    ")\n",
    "\n",
    "if result.ok:\n",
    "    print(\"Congratulations your results have been reported back to CV Studio!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SVM model to a file\n",
    "joblib.dump(svm.best_estimator_, \"svm.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's save the model back to CV Studio\n",
    "result = cvstudioClient.uploadModel(\"svm.joblib\", {\"svm_best\": svm.best_estimator_})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
