{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>KNN Image Classification with OpenCV and <a href=\"https://vision.skills.network/\"> Computer Vision Learning Studio (CV Studio) </a></h2>\n",
    "<h3>Project: Training_an_image_classifier_with_KNN</h3>\n",
    "<h3>Training Run: Train - KNN image classifier</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn how to train a K-Nearest Neighbours (k-NN), a supervised Machine Learning algorithm to classify your images. KNN learns from a labeled training set by taking in the training data along with its labels and learns to map the input to its desired output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be classifying cat and dog images using <code>OpenCV</code> and <a href=\"https://vision.skills.network/\"> Computer Vision Learning Studio (CV Studio)</a>. CV Studio is a fast, easy and collaborative open-source Computer Vision tool for teams and individuals. You can upload your datasets and label them yourself. If you created a separate folder for each image class, the tool will do the labeling for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>This tool contains the following sections:\n",
    "        <ul>\n",
    "            <li>Import Libraries</li>\n",
    "            <li>Load Images in Python</li>\n",
    "            <li>Plotting an Image </li>\n",
    "            <li>Gray Scale Images </li>\n",
    "            <li>k-NN for Image classification </li>\n",
    "            <li>Save your model to CVStudio</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Important Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for data processing and visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for image pre-processing and classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries for OS and Cloud:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skillsnetwork import cvstudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Your Images and Annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's initialize and download the images from the project you just created in CV Studio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CV Studio Client\n",
    "cvstudioClient = cvstudio.CVStudio()\n",
    "\n",
    "# Download All Images\n",
    "cvstudioClient.downloadAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the annotations from the project you downloaded from CV Studio:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = cvstudioClient.get_annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the format of the annotations we've just downloaded. The following code will display only the first 5 annotations. The annotations will come in a JSON file. What you can see is the image name as the key and `dog` as label object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five = {\n",
    "    k: annotations[\"annotations\"][k] for k in list(annotations[\"annotations\"])[:5]\n",
    "}\n",
    "first_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Plot and Image\n",
    "We will train and classify your images using the k-NN classifier using the <code>OpenCV</code> library. Before we start, let's get the images and take a look at some of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick random images and take a look:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_filename = \"images/\" + random.choice(list(annotations[\"annotations\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot, read and show a random image using the `cv2.imread` and the `matplotlib` library.\n",
    "\n",
    "We will also change the color space to `RGB` so we can plot it since `OpenCV` reads images as `BGR`. Early developers at `OpenCV` chose `BGR` color format because it was the format that was popular among camera manufacturers and software providers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = cv2.imread(random_filename)\n",
    "## Convert to RGB\n",
    "image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "## Now plot the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you plot with sample_image, you will observe a difference in the color space\n",
    "## uncomment to try it out\n",
    "# plt.imshow(sample_image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform KNN on the dataset, we will need to process the data. I will use the sample image to explain each line of code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image to grayscale - grayscale simplifies the algorithm and reduces computational requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(sample_image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize image - resizing image helps the algorithm train faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_image = cv2.resize(sample_image, (32, 32))\n",
    "plt.imshow(sample_image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten image - makes the image a numpy array for the algorithm to handle and recognize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = sample_image.flatten()\n",
    "pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the Process Above for All Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat the same process above to load and process all the images you’ve annotated and label each picture. KNN is supervised machine learning algorithm, therefore we have to explicitly create labels for the machine.\n",
    "\n",
    "Depending on how much data you have, this will take a while to run...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(paths.list_images(\"images\"))\n",
    "train_images = []\n",
    "train_labels = []\n",
    "class_object = annotations[\"labels\"]\n",
    "\n",
    "# loop over the input images\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # read image\n",
    "    image = cv2.imread(image_path)\n",
    "    # make images gray\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # label image using the annotations\n",
    "    label = class_object.index(annotations[\"annotations\"][image_path[7:]][0][\"label\"])\n",
    "    tmp_label = annotations[\"annotations\"][image_path[7:]][0][\"label\"]\n",
    "    # resize image\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    # flatten the image\n",
    "    pixels = image.flatten()\n",
    "    # Append flattened image to\n",
    "    train_images.append(pixels)\n",
    "    train_labels.append(label)\n",
    "    print(\"Loaded...\", \"\\U0001F483\", \"Image\", str(i + 1), \"is a\", tmp_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of the <code>train_images</code> and <code>train_labels</code>. <code>OpenCV</code> only identifies arrays of type <code>float32</code> for the training samples and array of shape <code>(label size, 1)</code> for the training labels. We can do that by specifying <code>astype('float32')</code> on the numpy array of the training samples and convert the training labels to integers and <code>reshape</code> the array to <code>(label size, 1)</code>. When you print the <code>train_labels</code>, the array will look like this <code>[[1], [0], ..., [0]]</code></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images).astype(\"float32\")\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(int)\n",
    "train_labels = train_labels.reshape((train_labels.size, 1))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test set with a test size of your choice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "train_samples, test_samples, train_labels, test_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=test_size, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the KNN model, we will use the <code>cv2.ml.KNearest_create()</code> from the <code>OpenCV</code> library. We need to define how many nearest neighbors will be used for classification as a hyper-parameter k. This parameter k can be toggled with/tuned in the training or model validation process. Fit the training and test images and get the accuracy score of the model.\n",
    "\n",
    "We will try multiple values of <code>k</code> to find the optimal value for the dataset we have. <code>k</code> refers to the number of nearest neighbours to include in the majority of the voting process.\n",
    "\n",
    "<i>Note:</i> Depending on how large your dataset is, it may take a few seconds to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_datetime = datetime.now()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_samples, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "## get different values of K\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "k_result = []\n",
    "for k in k_values:\n",
    "    ret, result, neighbours, dist = knn.findNearest(test_samples, k=k)\n",
    "    k_result.append(result)\n",
    "flattened = []\n",
    "for res in k_result:\n",
    "    flat_result = [item for sublist in res for item in sublist]\n",
    "    flattened.append(flat_result)\n",
    "\n",
    "end_datetime = datetime.now()\n",
    "print(\"Training Duration: \" + str(end_datetime - start_datetime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get the accuracy value for each value of <code>k</code> i.e., how many percent of the images were classified correctly? We will create a confusion matrix for a more comprehensive classification model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an empty list to save accuracy and the cofusion matrix\n",
    "accuracy_res = []\n",
    "con_matrix = []\n",
    "## we will use a loop because we have multiple value of k\n",
    "for k_res in k_result:\n",
    "    label_names = [0, 1]\n",
    "    cmx = confusion_matrix(test_labels, k_res, labels=label_names)\n",
    "    con_matrix.append(cmx)\n",
    "    ## get values for when we predict accurately\n",
    "    matches = k_res == test_labels\n",
    "    correct = np.count_nonzero(matches)\n",
    "    ## calculate accuracy\n",
    "    accuracy = correct * 100.0 / result.size\n",
    "    accuracy_res.append(accuracy)\n",
    "## stor accuracy for later when we create the graph\n",
    "res_accuracy = {k_values[i]: accuracy_res[i] for i in range(len(k_values))}\n",
    "list_res = sorted(res_accuracy.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Quick Guide to the Confusion Matrix**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a performance measurement for classification problem. It is a table with a combination of predicted and actual values. On the y-axis, we have the `True` label and on the x-axis we have the `Predicted` label. This example will focus on a binary classifier, i.e. a yes or no model.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>&nbsp;</td>\n",
    "    <td>Predicted: NO</td>\n",
    "    <td>Predicted: YES</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: NO</td>\n",
    "    <td>30</td>\n",
    "    <td>30</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: YES</td>\n",
    "    <td>10</td>\n",
    "    <td>50</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "In this matrix, we can see that there are two classes. For example, if we were predicting if an image is a hotdog, \"yes\" will be a hotdog and \"no\" will be not a hotdog. We have 120 predictions and out of those times, the classifier predicted \"yes\" 80 times and \"no\" 40 times but really, there were 60 \"yes\"s and 60 \"no\"s.\n",
    "\n",
    "When we talk about confusion matrix, we talk about a few terms:\n",
    "* True Positive (TP): Our model predicted \"yes\", and it was actually \"yes\"\n",
    "* True Negative (TN): Our model predicted \"no\", and it was actually \"no\"\n",
    "* False Positive (FP): Our model predicted \"yes\", but it was actually \"no\"\n",
    "* False Negative (FN): Our model predicted \"no\", but it was actually \"yes\"\n",
    "\n",
    "Let's look at it in the context of our example:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>&nbsp;</td>\n",
    "    <td>Predicted: NO</td>\n",
    "    <td>Predicted: YES</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: NO</td>\n",
    "    <td>TN = 30</td>\n",
    "    <td>FP = 30</td>\n",
    "    <td>60</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>True: YES</td>\n",
    "    <td>FN = 10</td>\n",
    "    <td>TP = 50</td>\n",
    "    <td>60</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>&nbsp;</td>\n",
    "    <td>40</td>\n",
    "    <td>80</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Accuracy** is the number the model got right over the total number of predictions. This is (TP+TN)/Total Number of Oredictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the confusion matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "## for each value of k we will create a confusion matrix\n",
    "for array in con_matrix:\n",
    "    df_cm = pd.DataFrame(array)\n",
    "    sns.set(font_scale=1.4)  # for label size\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt=\".0f\")  # font size\n",
    "    t += 1\n",
    "    title = \"Confusion Matrix for k equals \" + str(t)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the accuracy to see which one is highest i.e., what percentage of images were classified correctly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot accuracy against\n",
    "x, y = zip(*list_res)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get the best value of <code>k</code> to train the model to test the model on our image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = max(list_res, key=lambda item: item[1])[0]\n",
    "k_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Report Our Results Back to CV Studio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"k_best\": k_best}\n",
    "result = cvstudioClient.report(\n",
    "    started=start_datetime,\n",
    "    completed=end_datetime,\n",
    "    parameters=parameters,\n",
    "    accuracy=list_res,\n",
    ")\n",
    "\n",
    "if result.ok:\n",
    "    print(\"Congratulations your results have been reported back to CV Studio!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the KNN model to a file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.save(\"knn_samples.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cvstudioClient.uploadModel(\"knn_samples.yml\", {\"k_best\": k_best})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
